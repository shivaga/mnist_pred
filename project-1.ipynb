{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading mnist data with labels as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = loadmat(\"mnist-original.mat\")\n",
    "mnist_data = mnist[\"data\"].T\n",
    "mnist_label = mnist[\"label\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of image is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Reshape the input image into a 2D array (28x28)\n",
    "index_image=0\n",
    "image_2d = mnist_data[index_image].reshape(28, 28)\n",
    "# Plot the image\n",
    "plt.imshow(image_2d, cmap='gray')  # Use cmap='gray' for grayscale images\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.show()\n",
    "print(\"The label of image is\",mnist_label[index_image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into the test and train dataset for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data into 28x28 images and normalize the pixel values to range [0, 1]\n",
    "images_data = mnist_data.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "mnist_label = to_categorical(mnist_label).astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_data, mnist_label, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Determine the input shape dynamically\n",
    "inputshape = X_train.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of image is [0 0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the input image into a 2D array (28x28)\n",
    "index_image=5\n",
    "image_2d = X_train[index_image].reshape(28, 28)\n",
    "# Plot the image\n",
    "plt.imshow(image_2d, cmap='gray')  # Use cmap='gray' for grayscale images\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.show()\n",
    "print(\"The label of image is\",y_train[index_image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=inputshape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - categorical_accuracy: 0.8995 - loss: 0.3259 - val_categorical_accuracy: 0.9754 - val_loss: 0.0792\n",
      "Epoch 2/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - categorical_accuracy: 0.9853 - loss: 0.0478 - val_categorical_accuracy: 0.9861 - val_loss: 0.0477\n",
      "Epoch 3/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - categorical_accuracy: 0.9889 - loss: 0.0330 - val_categorical_accuracy: 0.9890 - val_loss: 0.0371\n",
      "Epoch 4/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - categorical_accuracy: 0.9935 - loss: 0.0215 - val_categorical_accuracy: 0.9814 - val_loss: 0.0624\n",
      "Epoch 5/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - categorical_accuracy: 0.9938 - loss: 0.0191 - val_categorical_accuracy: 0.9897 - val_loss: 0.0343\n",
      "Epoch 6/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - categorical_accuracy: 0.9958 - loss: 0.0121 - val_categorical_accuracy: 0.9881 - val_loss: 0.0408\n",
      "Epoch 7/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - categorical_accuracy: 0.9970 - loss: 0.0097 - val_categorical_accuracy: 0.9852 - val_loss: 0.0574\n",
      "Epoch 8/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - categorical_accuracy: 0.9969 - loss: 0.0091 - val_categorical_accuracy: 0.9884 - val_loss: 0.0496\n",
      "Epoch 9/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - categorical_accuracy: 0.9977 - loss: 0.0070 - val_categorical_accuracy: 0.9909 - val_loss: 0.0398\n",
      "Epoch 10/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - categorical_accuracy: 0.9982 - loss: 0.0055 - val_categorical_accuracy: 0.9876 - val_loss: 0.0550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x293af9b90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - categorical_accuracy: 0.9876 - loss: 0.0568\n",
      "Test Accuracy: 0.9876428842544556\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
